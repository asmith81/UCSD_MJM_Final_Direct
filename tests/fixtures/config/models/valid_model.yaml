model:
  name: "test_model"
  type: "llm"
  parameters:
    temperature: 0.7
    max_tokens: 100
    top_p: 0.9
    presence_penalty: 0.0
    frequency_penalty: 0.0 